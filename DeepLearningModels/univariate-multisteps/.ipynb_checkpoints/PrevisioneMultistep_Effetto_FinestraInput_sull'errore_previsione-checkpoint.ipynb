{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/alket/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "from pandas.plotting import lag_plot\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from math import sqrt\n",
    "# univariate lstm example\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras import metrics\n",
    "\n",
    "\n",
    "data = pd.read_csv('/Users/alket/Desktop/dati/new_data_backfill_forwfill.csv',index_col = 0)\n",
    "\n",
    "agg_by_cell = data.groupby(by = ['cell_num'])\n",
    "one_cell = agg_by_cell.get_group('486-1252')\n",
    "series = one_cell['nr_people'].values\n",
    "print(type(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n"
     ]
    }
   ],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "         # find the end of this pattern\n",
    "         end_ix = i + n_steps_in\n",
    "         out_end_ix = end_ix + n_steps_out\n",
    "         # check if we are beyond the sequence\n",
    "         if out_end_ix > len(sequence):\n",
    "             break\n",
    "         # gather input and output parts of the pattern\n",
    "         seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "         X.append(seq_x)\n",
    "         y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "dict2data={} \n",
    "count = 0\n",
    "\n",
    "n_steps_in, n_steps_out = 75, 16\n",
    "\n",
    "for i,k in agg_by_cell:\n",
    "    cell = i\n",
    "    \n",
    "    serie_dati = k['nr_people'].values\n",
    "    \n",
    "    # split into samples\n",
    "    X, y = split_sequence(serie_dati, n_steps_in, n_steps_out)\n",
    "    \n",
    "    # train-validation-test\n",
    "    train_X, test_X = X[:9000], X[9000:]\n",
    "    train_y, test_y = y[:9000], y[9000:]\n",
    "    #print(len(train_X), len(train_y), len(test_X), len(test_y), len(val_X), len(val_y))\n",
    "    \n",
    "    #define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, activation='relu', input_dim=n_steps_in)) \n",
    "    model.add(Dense(n_steps_out))\n",
    "\n",
    "    #opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # fit model\n",
    "    model.fit(train_X, train_y, batch_size=64, epochs=200, verbose=0)\n",
    "    \n",
    "    # predict and compute error\n",
    "    expected = y\n",
    "    predicted = []\n",
    "    for i in range(len(X)):\n",
    "        x_input = X[i].reshape((1, n_steps_in))\n",
    "        yhat = model.predict(x_input, verbose=0)   \n",
    "        predicted.append(np.around(yhat[0], decimals=1)) \n",
    "    \n",
    "    error = abs(expected - predicted)\n",
    "    #print(difference.shape[0], difference.shape[1])\n",
    "\n",
    "    # comment line below to see all the boxplots for every number of steps from 1 to n_steps_out\n",
    "    error =  np.reshape(error, error.shape[0] * error.shape[1])\n",
    "    \n",
    "    # collect data 2 dictionary\n",
    "    minimum = np.amin(error)   \n",
    "    per75 = np.percentile(error, 75)\n",
    "    per50 = np.percentile(error, 50)\n",
    "    per25 = np.percentile(error, 25)\n",
    "    maximum = np.amax(error)\n",
    "    l5i = [minimum, per25, per50, per75, maximum]\n",
    "    #l5i = ','.join(l5i)\n",
    "    dict2data[cell] = l5i\n",
    "    \n",
    "    #plt.figure(figsize = (16,2))\n",
    "    #plt.boxplot(error, vert= False);\n",
    "    #plt.show()\n",
    "    count +=1\n",
    "    print(count)\n",
    "with open('MLP_MultistepForcast_Variabilit√†Errore_75_16.csv', 'w') as f:\n",
    "    for key, value in dict2data.items():\n",
    "        f.write('%s:%s\\n' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
