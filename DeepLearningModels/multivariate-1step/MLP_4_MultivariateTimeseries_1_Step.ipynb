{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsone 1 Step per serie multivariata usando MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "from pandas.plotting import lag_plot\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from math import sqrt\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from keras import metrics\n",
    "\n",
    "data = pd.read_csv('/Users/alket/Desktop/dati/new_data_backfill_forwfill.csv',index_col = 0)\n",
    "\n",
    "# preparazione dati per due celle\n",
    "agg_by_cell = data.groupby(by = ['cell_num'])\n",
    "cell_1 = agg_by_cell.get_group('486-1252')\n",
    "cell_2 = agg_by_cell.get_group('486-1256')\n",
    "cell_3 = agg_by_cell.get_group('486-1258')\n",
    "# define input sequence\n",
    "series1 = cell_1['nr_people'].values\n",
    "series2 = cell_2['nr_people'].values\n",
    "series3 = cell_3['nr_people'].values\n",
    "print(type(series2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11808, 4)\n",
      "[[ 36.  43.  42. 121.]\n",
      " [ 36.  43.  42. 121.]\n",
      " [ 34.  40.  40. 114.]\n",
      " [ 33.  39.  39. 111.]] [ 32.  37.  37. 106.]\n",
      "[[ 36.  43.  42. 121.]\n",
      " [ 34.  40.  40. 114.]\n",
      " [ 33.  39.  39. 111.]\n",
      " [ 32.  37.  37. 106.]] [ 33.  37.  37. 107.]\n"
     ]
    }
   ],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# define input sequence\n",
    "out_seq = np.array([series1[i]+series2[i]+series3[i] for i in range(len(series1))]) # convert to [rows, columns] structure\n",
    "series1 = series1.reshape((len(series1), 1))\n",
    "series2 = series2.reshape((len(series2), 1))\n",
    "series3 = series3.reshape((len(series3), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "\n",
    "# horizontally stack columns\n",
    "dataset = hstack((series1, series2, series3, out_seq))\n",
    "print(dataset.shape)\n",
    "# choose a number of time steps\n",
    "n_steps = 4\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps)\n",
    "# summarize the data\n",
    "count = 0\n",
    "for i in range(len(X)):\n",
    "    count += 1\n",
    "    if count > 2: break\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividi dataset in Train-validation-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5783 5783 3542 3542 2479 2479\n",
      "[[ 59.  71.  49. 179.]\n",
      " [ 59.  71.  49. 179.]\n",
      " [ 59.  71.  48. 178.]\n",
      " [ 59.  71.  48. 178.]] [ 59.  71.  49. 179.]\n",
      "[[ 32.  37.  37. 106.]\n",
      " [ 32.  37.  37. 106.]\n",
      " [ 32.  36.  37. 105.]\n",
      " [ 34.  38.  37. 109.]] [ 34.  38.  37. 109.]\n",
      "[[ 57.  70.  45. 172.]\n",
      " [ 55.  66.  44. 165.]\n",
      " [ 55.  66.  44. 165.]\n",
      " [ 52.  63.  42. 157.]] [ 51.  61.  42. 154.]\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, test_size=0.3, random_state=1)\n",
    "print(len(train_X), len(train_y), len(test_X), len(test_y), len(val_X), len(val_y))\n",
    "\n",
    "count = 0\n",
    "for i in range(len(X)):\n",
    "    print(train_X[i],train_y[i])\n",
    "    count +=1\n",
    "    if count >= 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5783\n"
     ]
    }
   ],
   "source": [
    "# flatten input\n",
    "n_input = train_X.shape[1] * train_X.shape[2]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_input))\n",
    "n_output = train_y.shape[1]\n",
    "print(len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten input\n",
    "n_input_test = test_X.shape[1] * test_X.shape[2]\n",
    "test_X = test_X.reshape((test_X.shape[0], n_input_test))\n",
    "n_output_test = test_y.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " - 0s - loss: 325.7128 - mean_absolute_error: 8.0935 - accuracy: 0.9604\n",
      "Epoch 2/200\n",
      " - 0s - loss: 30.8123 - mean_absolute_error: 4.0312 - accuracy: 1.0000\n",
      "Epoch 3/200\n",
      " - 0s - loss: 21.9790 - mean_absolute_error: 3.2957 - accuracy: 1.0000\n",
      "Epoch 4/200\n",
      " - 0s - loss: 16.3484 - mean_absolute_error: 2.7536 - accuracy: 1.0000\n",
      "Epoch 5/200\n",
      " - 0s - loss: 12.3264 - mean_absolute_error: 2.3516 - accuracy: 1.0000\n",
      "Epoch 6/200\n",
      " - 0s - loss: 9.8711 - mean_absolute_error: 2.1076 - accuracy: 1.0000\n",
      "Epoch 7/200\n",
      " - 0s - loss: 8.5138 - mean_absolute_error: 1.9636 - accuracy: 1.0000\n",
      "Epoch 8/200\n",
      " - 0s - loss: 7.9180 - mean_absolute_error: 1.9033 - accuracy: 1.0000\n",
      "Epoch 9/200\n",
      " - 0s - loss: 7.3714 - mean_absolute_error: 1.8425 - accuracy: 1.0000\n",
      "Epoch 10/200\n",
      " - 0s - loss: 7.1049 - mean_absolute_error: 1.8073 - accuracy: 1.0000\n",
      "Epoch 11/200\n",
      " - 0s - loss: 7.0619 - mean_absolute_error: 1.7976 - accuracy: 1.0000\n",
      "Epoch 12/200\n",
      " - 0s - loss: 7.0336 - mean_absolute_error: 1.7797 - accuracy: 1.0000\n",
      "Epoch 13/200\n",
      " - 0s - loss: 6.8229 - mean_absolute_error: 1.7574 - accuracy: 1.0000\n",
      "Epoch 14/200\n",
      " - 0s - loss: 6.7471 - mean_absolute_error: 1.7455 - accuracy: 1.0000\n",
      "Epoch 15/200\n",
      " - 0s - loss: 6.5150 - mean_absolute_error: 1.7034 - accuracy: 1.0000\n",
      "Epoch 16/200\n",
      " - 0s - loss: 6.4666 - mean_absolute_error: 1.6855 - accuracy: 1.0000\n",
      "Epoch 17/200\n",
      " - 0s - loss: 6.3980 - mean_absolute_error: 1.6702 - accuracy: 1.0000\n",
      "Epoch 18/200\n",
      " - 0s - loss: 6.3509 - mean_absolute_error: 1.6703 - accuracy: 1.0000\n",
      "Epoch 19/200\n",
      " - 0s - loss: 6.1251 - mean_absolute_error: 1.6260 - accuracy: 1.0000\n",
      "Epoch 20/200\n",
      " - 0s - loss: 6.2769 - mean_absolute_error: 1.6478 - accuracy: 1.0000\n",
      "Epoch 21/200\n",
      " - 0s - loss: 6.2414 - mean_absolute_error: 1.6439 - accuracy: 1.0000\n",
      "Epoch 22/200\n",
      " - 0s - loss: 6.3656 - mean_absolute_error: 1.6547 - accuracy: 1.0000\n",
      "Epoch 23/200\n",
      " - 0s - loss: 6.3175 - mean_absolute_error: 1.6654 - accuracy: 1.0000\n",
      "Epoch 24/200\n",
      " - 0s - loss: 6.1134 - mean_absolute_error: 1.6289 - accuracy: 1.0000\n",
      "Epoch 25/200\n",
      " - 0s - loss: 6.0650 - mean_absolute_error: 1.6164 - accuracy: 1.0000\n",
      "Epoch 26/200\n",
      " - 0s - loss: 6.1589 - mean_absolute_error: 1.6273 - accuracy: 1.0000\n",
      "Epoch 27/200\n",
      " - 0s - loss: 6.3880 - mean_absolute_error: 1.6762 - accuracy: 1.0000\n",
      "Epoch 28/200\n",
      " - 0s - loss: 6.1612 - mean_absolute_error: 1.6325 - accuracy: 1.0000\n",
      "Epoch 29/200\n",
      " - 0s - loss: 6.3850 - mean_absolute_error: 1.6722 - accuracy: 1.0000\n",
      "Epoch 30/200\n",
      " - 0s - loss: 5.9286 - mean_absolute_error: 1.6031 - accuracy: 1.0000\n",
      "Epoch 31/200\n",
      " - 0s - loss: 6.3555 - mean_absolute_error: 1.6747 - accuracy: 1.0000\n",
      "Epoch 32/200\n",
      " - 0s - loss: 5.9110 - mean_absolute_error: 1.6006 - accuracy: 1.0000\n",
      "Epoch 33/200\n",
      " - 0s - loss: 6.0701 - mean_absolute_error: 1.6155 - accuracy: 1.0000\n",
      "Epoch 34/200\n",
      " - 0s - loss: 6.2570 - mean_absolute_error: 1.6546 - accuracy: 1.0000\n",
      "Epoch 35/200\n",
      " - 0s - loss: 6.0712 - mean_absolute_error: 1.6259 - accuracy: 1.0000\n",
      "Epoch 36/200\n",
      " - 0s - loss: 5.7305 - mean_absolute_error: 1.5562 - accuracy: 1.0000\n",
      "Epoch 37/200\n",
      " - 0s - loss: 5.8871 - mean_absolute_error: 1.5890 - accuracy: 1.0000\n",
      "Epoch 38/200\n",
      " - 0s - loss: 6.3528 - mean_absolute_error: 1.6716 - accuracy: 1.0000\n",
      "Epoch 39/200\n",
      " - 0s - loss: 6.0753 - mean_absolute_error: 1.6159 - accuracy: 1.0000\n",
      "Epoch 40/200\n",
      " - 0s - loss: 5.8336 - mean_absolute_error: 1.5737 - accuracy: 1.0000\n",
      "Epoch 41/200\n",
      " - 0s - loss: 5.7842 - mean_absolute_error: 1.5704 - accuracy: 1.0000\n",
      "Epoch 42/200\n",
      " - 0s - loss: 6.6094 - mean_absolute_error: 1.7125 - accuracy: 1.0000\n",
      "Epoch 43/200\n",
      " - 0s - loss: 5.9814 - mean_absolute_error: 1.5977 - accuracy: 1.0000\n",
      "Epoch 44/200\n",
      " - 0s - loss: 5.9230 - mean_absolute_error: 1.5966 - accuracy: 1.0000\n",
      "Epoch 45/200\n",
      " - 0s - loss: 5.7844 - mean_absolute_error: 1.5645 - accuracy: 1.0000\n",
      "Epoch 46/200\n",
      " - 0s - loss: 5.7963 - mean_absolute_error: 1.5684 - accuracy: 1.0000\n",
      "Epoch 47/200\n",
      " - 0s - loss: 6.0357 - mean_absolute_error: 1.6122 - accuracy: 1.0000\n",
      "Epoch 48/200\n",
      " - 0s - loss: 5.8179 - mean_absolute_error: 1.5810 - accuracy: 1.0000\n",
      "Epoch 49/200\n",
      " - 0s - loss: 5.7814 - mean_absolute_error: 1.5548 - accuracy: 1.0000\n",
      "Epoch 50/200\n",
      " - 0s - loss: 5.8151 - mean_absolute_error: 1.5724 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      " - 0s - loss: 6.1760 - mean_absolute_error: 1.6269 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      " - 0s - loss: 5.7243 - mean_absolute_error: 1.5537 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      " - 0s - loss: 5.8071 - mean_absolute_error: 1.5640 - accuracy: 1.0000\n",
      "Epoch 54/200\n",
      " - 0s - loss: 5.8349 - mean_absolute_error: 1.5709 - accuracy: 1.0000\n",
      "Epoch 55/200\n",
      " - 0s - loss: 5.8919 - mean_absolute_error: 1.5766 - accuracy: 1.0000\n",
      "Epoch 56/200\n",
      " - 0s - loss: 5.8058 - mean_absolute_error: 1.5683 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      " - 0s - loss: 6.0904 - mean_absolute_error: 1.6187 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      " - 0s - loss: 5.7204 - mean_absolute_error: 1.5444 - accuracy: 1.0000\n",
      "Epoch 59/200\n",
      " - 0s - loss: 5.7114 - mean_absolute_error: 1.5591 - accuracy: 1.0000\n",
      "Epoch 60/200\n",
      " - 0s - loss: 5.8346 - mean_absolute_error: 1.5679 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      " - 0s - loss: 5.9723 - mean_absolute_error: 1.5890 - accuracy: 1.0000\n",
      "Epoch 62/200\n",
      " - 0s - loss: 5.7399 - mean_absolute_error: 1.5429 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      " - 0s - loss: 5.8103 - mean_absolute_error: 1.5714 - accuracy: 1.0000\n",
      "Epoch 64/200\n",
      " - 0s - loss: 5.7974 - mean_absolute_error: 1.5709 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      " - 0s - loss: 5.7484 - mean_absolute_error: 1.5523 - accuracy: 1.0000\n",
      "Epoch 66/200\n",
      " - 0s - loss: 5.6721 - mean_absolute_error: 1.5364 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      " - 0s - loss: 5.6315 - mean_absolute_error: 1.5381 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      " - 0s - loss: 5.6942 - mean_absolute_error: 1.5427 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      " - 0s - loss: 5.7601 - mean_absolute_error: 1.5548 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      " - 0s - loss: 5.6623 - mean_absolute_error: 1.5359 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      " - 0s - loss: 5.9483 - mean_absolute_error: 1.5849 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      " - 0s - loss: 5.7714 - mean_absolute_error: 1.5561 - accuracy: 1.0000\n",
      "Epoch 73/200\n",
      " - 0s - loss: 5.8766 - mean_absolute_error: 1.5643 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      " - 0s - loss: 5.7863 - mean_absolute_error: 1.5592 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      " - 0s - loss: 5.7973 - mean_absolute_error: 1.5616 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      " - 0s - loss: 5.7335 - mean_absolute_error: 1.5519 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      " - 0s - loss: 5.7755 - mean_absolute_error: 1.5432 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      " - 0s - loss: 5.6257 - mean_absolute_error: 1.5343 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      " - 0s - loss: 5.6845 - mean_absolute_error: 1.5458 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      " - 0s - loss: 5.7071 - mean_absolute_error: 1.5468 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      " - 0s - loss: 5.6992 - mean_absolute_error: 1.5469 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      " - 0s - loss: 5.6920 - mean_absolute_error: 1.5459 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      " - 0s - loss: 5.6553 - mean_absolute_error: 1.5312 - accuracy: 1.0000\n",
      "Epoch 84/200\n",
      " - 0s - loss: 5.7988 - mean_absolute_error: 1.5576 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      " - 0s - loss: 5.6657 - mean_absolute_error: 1.5500 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      " - 0s - loss: 5.7122 - mean_absolute_error: 1.5380 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      " - 0s - loss: 5.6323 - mean_absolute_error: 1.5362 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      " - 0s - loss: 5.6254 - mean_absolute_error: 1.5366 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      " - 0s - loss: 5.7552 - mean_absolute_error: 1.5523 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      " - 0s - loss: 5.9656 - mean_absolute_error: 1.5856 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      " - 0s - loss: 5.9118 - mean_absolute_error: 1.5807 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      " - 0s - loss: 5.7806 - mean_absolute_error: 1.5653 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      " - 0s - loss: 5.6675 - mean_absolute_error: 1.5415 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      " - 0s - loss: 5.6941 - mean_absolute_error: 1.5450 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      " - 0s - loss: 5.6170 - mean_absolute_error: 1.5346 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      " - 0s - loss: 5.6886 - mean_absolute_error: 1.5383 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      " - 0s - loss: 5.6913 - mean_absolute_error: 1.5397 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      " - 0s - loss: 5.7371 - mean_absolute_error: 1.5670 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      " - 0s - loss: 5.7714 - mean_absolute_error: 1.5565 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      " - 0s - loss: 5.6818 - mean_absolute_error: 1.5457 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      " - 0s - loss: 5.6646 - mean_absolute_error: 1.5384 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      " - 0s - loss: 5.6796 - mean_absolute_error: 1.5391 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      " - 0s - loss: 5.7026 - mean_absolute_error: 1.5452 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      " - 0s - loss: 5.7494 - mean_absolute_error: 1.5572 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      " - 0s - loss: 5.7312 - mean_absolute_error: 1.5537 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      " - 0s - loss: 5.7288 - mean_absolute_error: 1.5479 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      " - 0s - loss: 5.6238 - mean_absolute_error: 1.5300 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      " - 0s - loss: 5.5753 - mean_absolute_error: 1.5202 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      " - 0s - loss: 5.6481 - mean_absolute_error: 1.5389 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      " - 0s - loss: 5.7631 - mean_absolute_error: 1.5585 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      " - 0s - loss: 5.6068 - mean_absolute_error: 1.5279 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      " - 0s - loss: 5.5988 - mean_absolute_error: 1.5307 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      " - 0s - loss: 5.8199 - mean_absolute_error: 1.5628 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      " - 0s - loss: 5.5455 - mean_absolute_error: 1.5168 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      " - 0s - loss: 5.7401 - mean_absolute_error: 1.5654 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      " - 0s - loss: 5.6990 - mean_absolute_error: 1.5501 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      " - 0s - loss: 5.8927 - mean_absolute_error: 1.5803 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      " - 0s - loss: 5.5462 - mean_absolute_error: 1.5184 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      " - 0s - loss: 5.6776 - mean_absolute_error: 1.5369 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      " - 0s - loss: 5.7016 - mean_absolute_error: 1.5380 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      " - 0s - loss: 5.6667 - mean_absolute_error: 1.5392 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      " - 0s - loss: 5.6813 - mean_absolute_error: 1.5431 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      " - 0s - loss: 5.6372 - mean_absolute_error: 1.5432 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      " - 0s - loss: 5.6018 - mean_absolute_error: 1.5195 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      " - 0s - loss: 5.7961 - mean_absolute_error: 1.5633 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      " - 0s - loss: 5.7357 - mean_absolute_error: 1.5511 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      " - 0s - loss: 5.6383 - mean_absolute_error: 1.5316 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      " - 0s - loss: 5.6434 - mean_absolute_error: 1.5329 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      " - 0s - loss: 5.6028 - mean_absolute_error: 1.5276 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      " - 0s - loss: 5.6427 - mean_absolute_error: 1.5413 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      " - 0s - loss: 5.7340 - mean_absolute_error: 1.5486 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      " - 0s - loss: 5.7180 - mean_absolute_error: 1.5482 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      " - 0s - loss: 5.6634 - mean_absolute_error: 1.5399 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      " - 0s - loss: 5.6852 - mean_absolute_error: 1.5394 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      " - 0s - loss: 5.7796 - mean_absolute_error: 1.5576 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      " - 0s - loss: 5.6943 - mean_absolute_error: 1.5421 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      " - 0s - loss: 5.5978 - mean_absolute_error: 1.5233 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      " - 0s - loss: 5.6725 - mean_absolute_error: 1.5378 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      " - 0s - loss: 5.7230 - mean_absolute_error: 1.5574 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      " - 0s - loss: 5.9100 - mean_absolute_error: 1.5876 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      " - 0s - loss: 5.5568 - mean_absolute_error: 1.5230 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      " - 0s - loss: 5.8137 - mean_absolute_error: 1.5680 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      " - 0s - loss: 5.5933 - mean_absolute_error: 1.5284 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      " - 0s - loss: 5.5635 - mean_absolute_error: 1.5204 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      " - 0s - loss: 5.5531 - mean_absolute_error: 1.5222 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      " - 0s - loss: 5.5601 - mean_absolute_error: 1.5168 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      " - 0s - loss: 5.6803 - mean_absolute_error: 1.5408 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      " - 0s - loss: 5.7347 - mean_absolute_error: 1.5442 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      " - 0s - loss: 5.6202 - mean_absolute_error: 1.5241 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      " - 0s - loss: 5.5580 - mean_absolute_error: 1.5152 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      " - 0s - loss: 5.6054 - mean_absolute_error: 1.5322 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      " - 0s - loss: 5.4581 - mean_absolute_error: 1.4981 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      " - 0s - loss: 5.4903 - mean_absolute_error: 1.5048 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      " - 0s - loss: 5.7174 - mean_absolute_error: 1.5457 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      " - 0s - loss: 5.8412 - mean_absolute_error: 1.5627 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      " - 0s - loss: 5.7751 - mean_absolute_error: 1.5582 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      " - 0s - loss: 5.5866 - mean_absolute_error: 1.5277 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      " - 0s - loss: 5.6206 - mean_absolute_error: 1.5331 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      " - 0s - loss: 5.6165 - mean_absolute_error: 1.5252 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      " - 0s - loss: 5.7460 - mean_absolute_error: 1.5509 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      " - 0s - loss: 5.6092 - mean_absolute_error: 1.5275 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      " - 0s - loss: 5.5706 - mean_absolute_error: 1.5319 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      " - 0s - loss: 5.6578 - mean_absolute_error: 1.5316 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      " - 0s - loss: 5.7250 - mean_absolute_error: 1.5485 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      " - 0s - loss: 5.4490 - mean_absolute_error: 1.4976 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      " - 0s - loss: 5.6857 - mean_absolute_error: 1.5402 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      " - 0s - loss: 5.5654 - mean_absolute_error: 1.5192 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      " - 0s - loss: 5.8764 - mean_absolute_error: 1.5756 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      " - 0s - loss: 5.5803 - mean_absolute_error: 1.5189 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      " - 0s - loss: 5.7628 - mean_absolute_error: 1.5508 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      " - 0s - loss: 5.5460 - mean_absolute_error: 1.5198 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      " - 0s - loss: 5.5098 - mean_absolute_error: 1.5089 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      " - 0s - loss: 5.5904 - mean_absolute_error: 1.5193 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      " - 0s - loss: 5.7211 - mean_absolute_error: 1.5544 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      " - 0s - loss: 5.7215 - mean_absolute_error: 1.5457 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      " - 0s - loss: 5.6822 - mean_absolute_error: 1.5377 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      " - 0s - loss: 5.6544 - mean_absolute_error: 1.5348 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      " - 0s - loss: 5.5406 - mean_absolute_error: 1.5167 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      " - 0s - loss: 5.5752 - mean_absolute_error: 1.5180 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      " - 0s - loss: 5.6087 - mean_absolute_error: 1.5277 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      " - 0s - loss: 5.7588 - mean_absolute_error: 1.5514 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      " - 0s - loss: 5.5487 - mean_absolute_error: 1.5133 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      " - 0s - loss: 5.6936 - mean_absolute_error: 1.5467 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      " - 0s - loss: 5.6712 - mean_absolute_error: 1.5392 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      " - 0s - loss: 5.6594 - mean_absolute_error: 1.5385 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      " - 0s - loss: 5.6341 - mean_absolute_error: 1.5296 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      " - 0s - loss: 5.4996 - mean_absolute_error: 1.5125 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      " - 0s - loss: 5.6034 - mean_absolute_error: 1.5325 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      " - 0s - loss: 5.6385 - mean_absolute_error: 1.5325 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      " - 0s - loss: 5.5735 - mean_absolute_error: 1.5151 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      " - 0s - loss: 5.7188 - mean_absolute_error: 1.5477 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      " - 0s - loss: 5.4700 - mean_absolute_error: 1.5011 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      " - 0s - loss: 5.5434 - mean_absolute_error: 1.5153 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      " - 0s - loss: 5.6062 - mean_absolute_error: 1.5272 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      " - 0s - loss: 5.5464 - mean_absolute_error: 1.5102 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      " - 0s - loss: 5.6052 - mean_absolute_error: 1.5248 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      " - 0s - loss: 5.5877 - mean_absolute_error: 1.5148 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/200\n",
      " - 0s - loss: 5.5366 - mean_absolute_error: 1.5085 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      " - 0s - loss: 5.5496 - mean_absolute_error: 1.5163 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      " - 0s - loss: 5.6701 - mean_absolute_error: 1.5329 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a2c62ced0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_dim=n_input)) \n",
    "model.add(Dense(n_output_test))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[metrics.mae, 'accuracy'])\n",
    "# fit model\n",
    "model.fit(train_X, train_y, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcolo dell'errore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3542\n",
      "14168\n",
      "Mean Absolute Error =  1.5533870667942764\n"
     ]
    }
   ],
   "source": [
    "# compute error\n",
    "predicted = np.array([])\n",
    "\n",
    "for i in range(len(test_X)):\n",
    "    x_input = test_X[i].reshape((1, n_input_test))\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    #print(yhat[0])\n",
    "    predicted = np.append(predicted, yhat[0])   \n",
    "\n",
    "expected = test_y  \n",
    "\n",
    "print(len(expected))\n",
    "print(len(predicted))\n",
    "expected = np.reshape(expected, predicted.shape[0])\n",
    "\n",
    "# abs difference\n",
    "difference = abs((expected - predicted))\n",
    "print('Mean Absolute Error = ', np.mean(difference))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafico distribuzione errore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show boxplot\n",
    "plt.figure(figsize = (14,2))\n",
    "plt.boxplot(difference, vert= False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fermare il traning al momento giusto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_6 to have shape (1,) but got array with shape (4,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-500f64c2d6cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_6 to have shape (1,) but got array with shape (4,)"
     ]
    }
   ],
   "source": [
    "# import EarlyStopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "# import metrics\n",
    "from keras import metrics\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=n_steps * n_steps, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[metrics.mae, 'accuracy'])\n",
    "\n",
    "# patient early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "\n",
    "# fit model\n",
    "history = model.fit(train_X, train_y, validation_data=(val_X, val_y), epochs=4000, verbose=0, callbacks=[es]) \n",
    "\n",
    "# evaluate the model\n",
    "train_acc = model.evaluate(train_X, train_y, verbose=1)\n",
    "\n",
    "val_acc = model.evaluate(val_X, val_y, verbose=1)\n",
    "print(train_acc, val_acc)\n",
    "print(model.metrics_names)\n",
    "print('Train: %.3f, Val: %.3f' % (train_acc[2], val_acc[2]))\n",
    "print(model.metrics_names)\n",
    "# plot loss learning curves\n",
    "plt.figure(figsize = (15, 8))\n",
    "plt.subplot(211)\n",
    "plt.title('MSE Loss', pad=-40)\n",
    "plt.plot(history.history['loss'], label='train') \n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "\n",
    "# plot accuracy learning curves\n",
    "plt.subplot(212)\n",
    "plt.title('Accuracy', pad=-40)\n",
    "plt.plot(history.history['accuracy'], label='train') \n",
    "plt.plot(history.history['val_accuracy'], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
